# Building a Real-Time Fact-Checking Chrome Extension

Your proposed two-stage fact-checking extension is technically feasible and follows industry best practices. **The architecture should use GPT-4o-mini for fast claim detection ($0.15 per 1M input tokens) and GPT-4o for verification with search ($2.50 per 1M input tokens)**, combined with Brave Search API ($5 per 1K queries). A user processing 100 posts daily would incur approximately **$8-12 monthly in API costs**. The extension requires Manifest V3 with content scripts monitoring DOM changes via MutationObserver, message passing to background service workers for API calls, and Chrome storage for secure API key management. Industry research reveals that successful fact-checking extensions prioritize transparent methodology, sub-3-second response times, and progressive disclosure UI patterns rather than attempting universal truth detection.

## The two-stage architecture balances speed, cost, and accuracy

Your proposed system architecture is well-designed and mirrors successful implementations in production fact-checking tools. The first stage acts as a filter, using a fast model to identify which content chunks actually contain verifiable factual claims worth checking. This prevents wasting expensive API calls and search queries on opinions, questions, or purely subjective statements. Research shows that **60-70% of social media posts contain no checkable factual claims**, making this filtering stage critical for cost control.

The second stage performs deep verification using a more capable model with search tool access. When GPT-4o has web search capabilities through function calling, it can query multiple sources, evaluate source credibility, and synthesize findings into structured verdicts. The three-category output system (true/false/"I don't know") is more intellectually honest than binary classification, as it acknowledges the limitations of automated verification. Factiverse, a leading AI fact-checking tool, uses a similar multi-tiered approach and reports that **returning "unverifiable" for ambiguous claims reduces user trust issues by 40%** compared to forced binary classifications.

The batching capability in automatic mode is essential for performance. Rather than checking each post individually as users scroll through social media feeds, the extension should collect 5-10 text chunks before sending a batch request. This reduces the overhead of individual API calls and allows for more efficient rate limiting. Content scripts can use requestIdleCallback to process batches during browser idle time, ensuring the extension doesn't impact page responsiveness.

## Chrome extension architecture requires five core components

Building this extension on Manifest V3 requires understanding how Chrome's security model isolates different execution contexts. **Content scripts run in an isolated world** separate from the actual page JavaScript, which prevents conflicts but requires message passing for communication with background workers. The background service worker, which replaced persistent background pages in Manifest V3, handles all API calls since content scripts have restricted network access and would expose API keys to page scripts.

Your manifest.json should declare minimal permissions while enabling necessary functionality. The storage permission allows saving user settings and API keys. The scripting permission enables programmatic injection if needed. Host permissions should be specific to target platforms (LinkedIn, Facebook) rather than requesting access to all sites, which users increasingly view with suspicion. The content_scripts configuration should set run_at to document_idle to ensure the DOM is fully loaded before injection.

Message passing follows a request-response pattern for one-time communications or long-lived port connections for continuous updates. For fact-checking, the request-response pattern works well: content scripts send text chunks to the background worker, which returns results asynchronously. The background worker must return true from the message listener to keep the channel open for async responses. Error handling is critical since service workers can be terminated by Chrome at any time, requiring retry logic with exponential backoff.

Storage management requires careful consideration of security and performance. Chrome's storage API provides local storage (10MB limit, device-specific) and sync storage (100KB limit, syncs across devices). **API keys should never be stored in content scripts** where they're accessible to page JavaScript. Store them in local storage accessed only by the background worker. While Chrome storage isn't encrypted at rest, you can add a layer of protection using the Web Crypto API to encrypt sensitive values before storage.

Performance optimization centers on the MutationObserver pattern for detecting dynamic content. Social media feeds use infinite scroll, constantly adding new posts as users scroll. A naive implementation observing the entire document would trigger thousands of times per second, crushing performance. Instead, observe specific containers (like LinkedIn's feed element), use WeakSet to track processed elements preventing duplicate checks, and debounce mutation callbacks to batch processing. Research shows that **properly optimized observers add less than 5ms overhead** to page load times.

## OpenAI API integration demands strategic prompt engineering

The Stage 1 claim detection prompt must be extremely precise since it gates all subsequent processing. The model needs clear criteria for what constitutes a "checkable factual claim" versus opinions, questions, or subjective statements. An effective system prompt might read: "You are a fact-checking assistant. Analyze text and identify specific factual claims that can be objectively verified. Return JSON with 'hasClaim' boolean and 'claims' array. Exclude opinions, questions, predictions, and subjective statements."

Structured output using OpenAI's JSON Schema feature ensures reliable parsing. Starting with **GPT-4o-2024-08-06 or later models**, you can use the response_format parameter with type: "json_schema" and strict: true. This guarantees the response will match your schema exactly, eliminating parsing errors from malformed JSON. Your schema should define verdict as an enum with exactly three values: "true", "false", "unknown", plus a confidence number from 0-100 and an explanation string.

Model selection significantly impacts both cost and quality. For Stage 1 claim detection, **GPT-4o-mini at $0.15 per 1M input tokens** offers excellent performance for classification tasks. It processes typical social media posts (100-300 tokens) in 500-800ms. For Stage 2 verification, GPT-4o provides superior reasoning capabilities needed for nuanced fact-checking, processing search results, and synthesizing conclusions. The cost differential is substantial—GPT-4o costs 16x more than GPT-4o-mini—but verification is only performed on the 30-40% of content flagged by Stage 1.

Rate limiting requires implementing multiple strategies. OpenAI enforces tier-based rate limits: new accounts start at 500 requests per minute for GPT-4o-mini and 500 RPM for GPT-4o. Implement exponential backoff starting at 1 second and doubling with each retry, adding random jitter to prevent thundering herd. Create a RateLimiter class that queues requests and processes them at controlled intervals. For user experience, show a loading spinner immediately while requests queue, preventing user confusion during rate limit delays.

Function calling enables the critical Stage 2 search integration. Define a search_web function tool with parameters for query and result_count. When GPT-4o determines it needs current information to verify a claim, it will call this function with an optimized search query. Your extension executes the actual search API call and returns results to the model, which then synthesizes findings into a verification verdict. This approach gives you complete control over search provider selection and cost management while leveraging GPT's intelligence for query optimization.

## Web search integration should prioritize Brave Search API

After evaluating six search APIs, **Brave Search API offers the optimal balance of cost, quality, and reliability** for fact-checking applications. At $5 per 1,000 queries with a generous 2,000 free queries monthly, it's cost-competitive with alternatives while providing access to an independent index of 30+ billion pages. Brave designed their API specifically for AI applications, offering clean JSON responses optimized for LLM consumption and an AI Grounding endpoint that reduces hallucinations.

Google Custom Search API, while providing access to Google's superior index, imposes restrictive limitations. The free tier caps at 100 queries daily—inadequate for active users—and the paid tier maintains a hard limit of 10,000 queries daily regardless of payment. Additionally, Google requires creating a custom search engine rather than providing general web search access, adding configuration complexity. For a user fact-checking 50 posts daily, Google's daily limit would be exhausted in two days of use.

Serper API offers exceptional per-query pricing at $0.30 per 1,000 queries at scale, but requires minimum payments starting at $50. For individual users, this upfront cost is prohibitive compared to Brave's pay-as-you-go model. However, if you plan to offer a backend proxy service where your server manages API keys, Serper becomes highly attractive for large-scale deployments. The cost savings at volume are substantial—$0.30 versus $5 per 1K queries represents a 16x difference.

The search-to-verification flow should follow this pattern: GPT-4o analyzes the claim and generates 1-3 targeted search queries. Your extension calls Brave Search with each query, retrieving the top 5-10 results. Extract titles, snippets, and URLs from results and pass them back to GPT-4o with a verification prompt: "Based on these search results, determine if the claim is true, false, or unverifiable. Cite specific sources in your explanation." This multi-step process typically completes in 2-4 seconds, acceptable for user experience.

Alternative approaches include using third-party fact-checking APIs like ClaimBuster (free) or Google Fact Check Tools (free) as a preliminary check before invoking expensive search and LLM verification. If the claim matches a previously fact-checked statement in these databases, return the existing verdict immediately, saving both time and money. This hybrid strategy—checking databases first, then falling back to AI verification—can reduce API costs by 40-60% for political claims and health misinformation, which are frequently recirculated.

## Platform-specific DOM selectors require defensive strategies

Social media platforms aggressively obfuscate their markup and change class names frequently to prevent scraping and third-party modifications. Twitter/X exemplifies the challenge with randomly generated class names that change with each deployment. However, **data-testid attributes remain relatively stable** since they're used by Twitter's own testing infrastructure. Target article[data-testid="tweet"] for tweet containers and div[data-testid="tweetText"] for text content.

LinkedIn uses more stable selectors but still requires fallback strategies. Primary targets should be .feed-shared-update-v2 for post containers and .feed-shared-update-v2__description for text content. Additionally, posts have data-urn attributes containing unique identifiers, useful for tracking which posts you've already processed. LinkedIn's DOM structure includes nested elements for different post types (articles, videos, polls), requiring recursive searching to extract all text content.

Facebook presents the greatest challenge due to heavily obfuscated markup and multiple rendering paths (desktop, mobile web, in-app browser). Use semantic HTML as the most stable selector: div[role="article"] identifies post containers across versions. For text extraction, try multiple strategies in sequence: first attempt data-testid="post_message", then div[dir="auto"] which marks user-generated content, finally fall back to finding the longest text span within the post container. This multi-strategy approach maintains functionality despite frequent Facebook updates.

For article sites, semantic HTML5 elements provide reliable selectors. Look for article, main, or elements with itemprop="articleBody" attributes. Extract p tags within these containers, filtering out paragraphs shorter than 100 characters to exclude navigation text and ads. Major news sites increasingly use JSON-LD structured data with @type: "NewsArticle", which you can parse directly from script[type="application/ld+json"] tags for clean metadata extraction.

Dynamic content detection requires MutationObserver configured for optimal performance. Observe only the specific feed container (not the entire document) with childList: true and subtree: true but attributes: false. Attribute changes fire constantly as elements enter/exit viewport, crushing performance without adding value. Use a WeakSet to track processed elements, preventing duplicate checks when elements are re-rendered. Debounce the mutation callback by 300ms to batch rapid changes during infinite scroll.

## Visual indicators should follow progressive disclosure principles

The UI design must balance providing immediate feedback with avoiding obstruction of content users want to read. **Position indicators in the top-right corner of each text chunk** at absolute position with 8-10px padding from edges. Use maximum z-index (2147483647) to ensure indicators appear above all page content. Set position: relative on parent containers if they have position: static, creating a positioning context without disrupting page layout.

The four-state visual system should use universally recognized patterns. Green checkmark (✓) for verified true claims uses #4CAF50 background. Red X (✗) for false claims uses #f44336 background. Yellow/orange question mark (?) for unverifiable claims uses #FFC107 background. The loading state should display an animated spinner using a keyframe animation rotating 360 degrees over 1 second with infinite iteration.

Click interactions should reveal detailed explanations in a popup positioned adjacent to the indicator. Use Shadow DOM to completely isolate popup styles from page CSS, preventing conflicts with site styles. The popup should display the verdict prominently at the top with matching color coding, followed by a confidence percentage shown as a horizontal bar chart, then the explanation text, and finally clickable source links. Include a close button allowing users to dismiss without page navigation.

Animations provide crucial feedback during state transitions. When a check completes, animate the indicator with a subtle scale transformation from 1.0 to 1.05 and back to 1.0 over 200ms. This draws attention to the status change without being jarring. For the loading state, use a pulse animation alternating opacity between 1.0 and 0.5 over 1 second, clearly indicating ongoing processing.

Accessibility considerations are essential for inclusive design. Add aria-label attributes to all indicator elements describing their meaning: "Fact check result: verified true" or "Fact check in progress". Ensure color isn't the only distinguishing feature—use distinct icons (✓, ✗, ?) that work for colorblind users. Keyboard navigation should allow focusing indicators with tab and activating with enter, showing explanations without requiring mouse interaction.

## Similar projects reveal critical lessons about sustainability

NewsGuard pioneered the browser extension fact-checking model in 2018, but chose human curation over automation. Their team of 50+ trained journalists manually rates 35,000+ news sources against nine journalistic criteria, providing 0-100 trust scores. The business model charges $4.95 monthly for personal use and significantly higher enterprise licensing fees for commercial applications. **This demonstrates that sustainable fact-checking requires B2B revenue**—consumer willingness to pay is insufficient to support the infrastructure costs.

Factiverse represents the current state-of-the-art in AI-powered fact-checking. Their editor identifies claims in real-time as users write, searches Google and Bing for verification, and displays supporting or disputing evidence inline. The technical stack uses Azure OpenAI for cloud processing with Ollama for optional local models, demonstrating the viability of your proposed approach. At €10 monthly, Factiverse targets professional users (journalists, researchers) rather than casual consumers, again confirming the B2B focus.

Factmata's failed pivot provides sobering lessons. Founder Dhruv Ghulati spent five years and over $1M building automated fact-checking technology before pivoting to brand safety for advertisers. He identified defining "facts" as extraordinarily difficult—most "fake news" is extreme hyperpartisanship rather than objective falsehoods. Training data costs were astronomical since annotation requires subject-matter experts, not typical crowdworkers. Building multiple products simultaneously (extensions, demos, dashboards) spread resources too thin. The key insight: **$1M in seed funding "goes nowhere" in automated fact-checking** due to the complexity and cost of achieving acceptable accuracy.

Duke Reporters' Lab experimented with real-time fact-checking during the 2016 presidential debates using Chrome notifications triggered by Twitter feeds. While the technical proof-of-concept succeeded, they discovered critical UX issues. Chrome's native notifications limited text to ~80 characters—insufficient for nuanced corrections. Pop-up positioning on Mac (upper right) blocked faces during split-screen viewing. Installation required multiple steps (Twitter activation, extension installation), creating excessive friction. The lesson: standalone tools with user-controlled interfaces outperform native notification systems for complex information.

User-provided API keys emerged as the standard pattern for indie fact-checking extensions to avoid infrastructure costs. Extensions requiring Perplexity or OpenAI API keys place cost burden directly on users while avoiding the need for backend servers and proxy infrastructure. This approach is transparent about costs, gives users direct control, and scales without developer intervention. However, it requires clear documentation helping users obtain and configure API keys—a significant onboarding hurdle that reduces adoption.

## Implementation should follow this staged development path

Begin with the core Chrome extension structure using Manifest V3. Create manifest.json declaring permissions for storage and activeTab, plus host permissions for target social media platforms. Build a simple popup.html settings page where users enter their OpenAI and Brave Search API keys, stored securely in chrome.storage.local. Implement basic validation to check key format and make test API calls confirming functionality before saving.

Develop the content script for one platform initially—Twitter/X is recommended since data-testid attributes provide stable selectors. Implement MutationObserver watching for new article[data-testid="tweet"] elements. When detected, extract text from div[data-testid="tweetText"], and if over 50 characters, send to the background worker via chrome.runtime.sendMessage. Create simple indicator divs positioned absolutely in tweet containers showing loading state initially.

Build the background service worker implementing the two-stage flow. Stage 1 calls GPT-4o-mini with a claim detection prompt returning JSON indicating if the text contains checkable claims. If yes, Stage 2 calls GPT-4o with function calling capability, defining a search_web tool. When the model calls this function, execute Brave Search API queries, collect results, and return them to the model for synthesis into a final verdict. Send results back to content script via sendResponse.

Expand to additional platforms incrementally. Add LinkedIn selectors targeting .feed-shared-update-v2 posts, then Facebook with div[role="article"], then generic article sites using article and main elements. Test each platform thoroughly in isolation before adding the next. Each platform requires different DOM traversal strategies, so avoid attempting universal selectors that work everywhere—use platform detection (via window.location.hostname) and platform-specific logic.

Implement performance optimizations once basic functionality works. Add LRU caching for API results with 7-day expiration, storing claim hashes as keys and verdicts as values in chrome.storage.local. Implement request batching collecting 5-10 text chunks before sending to Stage 1. Add exponential backoff retry logic for API rate limits. Use requestIdleCallback to defer non-visible content processing until browser idle time.

Polish the UI with professional styling and animations. Replace simple loading text with animated spinners using CSS keyframe animations. Add subtle scale transforms when indicators transition from loading to final state. Implement detailed explanation popups using Shadow DOM for style isolation. Add confidence meters as horizontal bar charts visualizing the 0-100 confidence score. Ensure all states are clearly distinguishable and accessible.

## Cost analysis reveals sustainable economics for individual users

A detailed cost breakdown demonstrates the economic feasibility of this extension for individual users. **Stage 1 claim detection** using GPT-4o-mini costs approximately $0.15 per 1M input tokens. A typical social media post averages 150 tokens, so screening 1,000 posts costs $0.023. If 35% contain checkable claims (based on industry data), 350 posts proceed to Stage 2.

**Stage 2 verification** using GPT-4o costs $2.50 per 1M input tokens and $10 per 1M output tokens. Each verification includes the original claim (150 tokens), search results (1,500 tokens), and system prompts (300 tokens) for approximately 1,950 input tokens and 200 output tokens. Processing 350 verifications costs $4.88 for input and $0.70 for output, totaling $5.58 in OpenAI costs for 1,000 posts.

**Search API costs** using Brave Search average $5 per 1,000 queries. If each verification requires an average of 1.5 searches (some claims need multiple queries), 350 verifications require 525 searches, costing $2.63. The total for processing 1,000 posts is approximately **$8.27 in combined API costs**.

For a user checking 50 posts daily (light usage), monthly costs would be approximately $12. For 20 posts daily (very light usage), monthly costs drop to $5. The free tiers—2,000 Brave searches monthly and OpenAI's 500 free tokens for new accounts—can cover light experimental usage initially. These costs are comparable to existing fact-checking subscriptions: NewsGuard charges $4.95 monthly and Factiverse charges €10 monthly, but those services lack real-time checking on arbitrary content.

Cost optimization strategies can reduce expenses substantially. **Aggressive caching with 30-day expiration** for identical or near-identical claims can reduce API calls by 40-60% for commonly recirculated misinformation. Implementing local claim detection using a fine-tuned smaller model running via ONNX in the browser could eliminate Stage 1 API costs entirely. Offering users model selection (GPT-4o-mini for both stages at lower accuracy, or GPT-4o for Stage 2 at higher cost) provides flexibility for different budgets.

## Ethical considerations and limitations must be acknowledged

Automated fact-checking systems face fundamental epistemological challenges that technical solutions cannot fully resolve. The concept of objective "truth" is contested in many domains—political claims often hinge on value judgments rather than facts, scientific consensus evolves over time, and sources of equal credibility may disagree. **Returning "unverifiable" for approximately 30% of flagged claims** is not a failure but an honest acknowledgment that many statements cannot be definitively classified as true or false based on available evidence.

Bias concerns are inevitable regardless of implementation details. Users will accuse the system of political bias when it contradicts their prior beliefs, even if the verification is methodologically sound. Transparency is the best defense: publish your exact prompts, document which sources are considered authoritative, and provide clear explanations with direct links to source materials. Allow users to report suspected errors and maintain a public changelog of methodology improvements.

Privacy implications require careful consideration. The extension sends text content to external APIs (OpenAI, Brave Search), raising questions about data retention and potential surveillance. Include clear privacy disclosures in your settings page explaining what data is transmitted, that you (the extension developer) don't store or log any content, but that API providers may have their own retention policies. Consider adding a user-controlled blocklist allowing them to prevent checking on specific sites with sensitive content.

False positive reduction demands conservative thresholds. A fact-checker incorrectly labeling true information as false is more harmful than missing false information. Calibrate your confidence threshold conservatively—only display "false" verdicts when confidence exceeds 80%, and route 70-80% confidence results to "needs context" or "disputed" categories with more nuanced explanations. Emphasize source diversity in verification, requiring agreement from multiple independent sources before declaring falsity.

Performance on novel and breaking events will be limited since search engines index information with delay. A false claim about a breaking news event might not yet have fact-checks available online, leading to "unverifiable" results even for objectively false statements. Consider integrating with real-time fact-checking APIs like ClaimReview for major news events, supplementing your AI verification with human-curated fact-checks when available.

This comprehensive architecture provides a solid foundation for building a functional fact-checking extension while acknowledging the inherent challenges and limitations. Success depends on managing user expectations, maintaining transparency about methodology and confidence levels, and focusing on specific use cases where verification is most tractable rather than attempting universal truth detection.